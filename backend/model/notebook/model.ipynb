{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sqlite3\n",
    "import sys, traceback\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_consumption(db_path, table_name):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        print(\"successfully connected to database\")\n",
    "            \n",
    "    except:\n",
    "        print(\"Error in connecting database!\")\n",
    "        print(\"-\"*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print(\"-\"*60)\n",
    "    df = pd.read_sql('SELECT * FROM {}'.format(table_name), conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully connected to database\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_data</th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>...</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "      <th>RawTimeStamp</th>\n",
       "      <th>ConsumptionTimeStamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2549.026455</td>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>...</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-29 12:46:43</td>\n",
       "      <td>2023-05-29 14:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2631.455231</td>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-29 12:46:43</td>\n",
       "      <td>2023-05-29 14:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2603.736014</td>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-29 12:46:43</td>\n",
       "      <td>2023-05-29 14:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2769.680851</td>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-29 12:46:43</td>\n",
       "      <td>2023-05-29 14:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1411.996700</td>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-29 12:46:43</td>\n",
       "      <td>2023-05-29 14:32:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_data  battery_power  blue  clock_speed  dual_sim  fc  four_g   \n",
       "0  2549.026455            842     0          2.2         0   1       0  \\\n",
       "1  2631.455231           1021     1          0.5         1   0       1   \n",
       "2  2603.736014            563     1          0.5         1   2       1   \n",
       "3  2769.680851            615     1          2.5         0   0       0   \n",
       "4  1411.996700           1821     1          1.2         0  13       1   \n",
       "\n",
       "   int_memory  m_dep  mobile_wt  ...   ram  sc_h  sc_w  talk_time  three_g   \n",
       "0           7    0.6        188  ...  2549     9     7         19        0  \\\n",
       "1          53    0.7        136  ...  2631    17     3          7        1   \n",
       "2          41    0.9        145  ...  2603    11     2          9        1   \n",
       "3          10    0.8        131  ...  2769    16     8         11        1   \n",
       "4          44    0.6        141  ...  1411     8     2         15        1   \n",
       "\n",
       "   touch_screen  wifi  price_range         RawTimeStamp  ConsumptionTimeStamp  \n",
       "0             0     1            1  2023-05-29 12:46:43   2023-05-29 14:32:00  \n",
       "1             1     0            2  2023-05-29 12:46:43   2023-05-29 14:32:00  \n",
       "2             1     0            2  2023-05-29 12:46:43   2023-05-29 14:32:00  \n",
       "3             0     0            2  2023-05-29 12:46:43   2023-05-29 14:32:00  \n",
       "4             1     0            1  2023-05-29 12:46:43   2023-05-29 14:32:00  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_from_consumption(\"../../database/data.db\", \"CONSUMPTION\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   unique_data           2000 non-null   float64\n",
      " 1   battery_power         2000 non-null   int64  \n",
      " 2   blue                  2000 non-null   int64  \n",
      " 3   clock_speed           2000 non-null   float64\n",
      " 4   dual_sim              2000 non-null   int64  \n",
      " 5   fc                    2000 non-null   int64  \n",
      " 6   four_g                2000 non-null   int64  \n",
      " 7   int_memory            2000 non-null   int64  \n",
      " 8   m_dep                 2000 non-null   float64\n",
      " 9   mobile_wt             2000 non-null   int64  \n",
      " 10  n_cores               2000 non-null   int64  \n",
      " 11  pc                    2000 non-null   int64  \n",
      " 12  px_height             2000 non-null   int64  \n",
      " 13  px_width              2000 non-null   int64  \n",
      " 14  ram                   2000 non-null   int64  \n",
      " 15  sc_h                  2000 non-null   int64  \n",
      " 16  sc_w                  2000 non-null   int64  \n",
      " 17  talk_time             2000 non-null   int64  \n",
      " 18  three_g               2000 non-null   int64  \n",
      " 19  touch_screen          2000 non-null   int64  \n",
      " 20  wifi                  2000 non-null   int64  \n",
      " 21  price_range           2000 non-null   int64  \n",
      " 22  RawTimeStamp          2000 non-null   object \n",
      " 23  ConsumptionTimeStamp  2000 non-null   object \n",
      "dtypes: float64(3), int64(19), object(2)\n",
      "memory usage: 375.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 20) (2000,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop([\"unique_data\", \"RawTimeStamp\", \"ConsumptionTimeStamp\", \"price_range\"], axis=1)\n",
    "y_train = df.iloc[:,-3].values\n",
    "print(X.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer()\n",
    "X_train = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X = torch.from_numpy(X_train.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "        self.len = self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = Data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[2.9214e-01, 3.0400e-04, 4.2560e-04, 3.0400e-04, 0.0000e+00, 3.0400e-04,\n",
      "         1.7328e-02, 1.8240e-04, 3.4656e-02, 2.4320e-03, 9.1199e-04, 8.8463e-02,\n",
      "         4.3593e-01, 8.4572e-01, 5.4719e-03, 2.7360e-03, 2.1280e-03, 3.0400e-04,\n",
      "         3.0400e-04, 3.0400e-04],\n",
      "        [1.3326e-01, 2.5676e-04, 4.1081e-04, 2.5676e-04, 1.7973e-03, 2.5676e-04,\n",
      "         1.3095e-02, 7.7028e-05, 3.3892e-02, 1.0270e-03, 4.8784e-03, 1.4122e-01,\n",
      "         1.6561e-01, 9.6618e-01, 4.1081e-03, 2.5676e-04, 1.0270e-03, 2.5676e-04,\n",
      "         0.0000e+00, 2.5676e-04],\n",
      "        [2.6362e-01, 0.0000e+00, 1.3788e-04, 0.0000e+00, 2.7575e-04, 2.7575e-04,\n",
      "         1.1306e-02, 2.7575e-04, 3.9432e-02, 1.9303e-03, 1.6545e-03, 1.4091e-01,\n",
      "         2.9643e-01, 9.0612e-01, 4.6878e-03, 2.2060e-03, 3.3090e-03, 2.7575e-04,\n",
      "         2.7575e-04, 0.0000e+00],\n",
      "        [4.7120e-01, 0.0000e+00, 5.1887e-04, 3.2430e-04, 3.8915e-03, 3.2430e-04,\n",
      "         1.6863e-02, 9.7289e-05, 3.1132e-02, 6.4859e-04, 5.8373e-03, 6.0643e-02,\n",
      "         4.2515e-01, 7.6955e-01, 3.2430e-03, 3.2430e-04, 3.2430e-03, 3.2430e-04,\n",
      "         3.2430e-04, 3.2430e-04],\n",
      "        [4.2765e-01, 0.0000e+00, 2.5126e-04, 0.0000e+00, 1.5076e-03, 0.0000e+00,\n",
      "         1.0553e-02, 2.0101e-04, 1.0050e-01, 2.5126e-03, 3.5177e-03, 5.8846e-01,\n",
      "         6.3469e-01, 2.4021e-01, 6.0303e-03, 3.5177e-03, 5.0252e-03, 5.0252e-04,\n",
      "         0.0000e+00, 5.0252e-04],\n",
      "        [3.5445e-01, 2.2448e-04, 1.1224e-04, 2.2448e-04, 0.0000e+00, 0.0000e+00,\n",
      "         1.1224e-03, 4.4896e-05, 1.9754e-02, 1.5713e-03, 2.0203e-03, 3.0484e-01,\n",
      "         3.9037e-01, 7.9286e-01, 3.8161e-03, 2.4693e-03, 2.6937e-03, 0.0000e+00,\n",
      "         0.0000e+00, 2.2448e-04],\n",
      "        [8.5805e-01, 5.4723e-04, 2.7361e-04, 0.0000e+00, 8.7557e-03, 0.0000e+00,\n",
      "         1.8059e-02, 5.4723e-04, 8.2084e-02, 4.3778e-03, 1.0945e-02, 2.2601e-01,\n",
      "         3.5789e-01, 2.7799e-01, 2.7361e-03, 5.4723e-04, 3.2834e-03, 5.4723e-04,\n",
      "         5.4723e-04, 5.4723e-04],\n",
      "        [4.6496e-01, 3.5251e-04, 3.1726e-04, 0.0000e+00, 1.0575e-03, 3.5251e-04,\n",
      "         1.4453e-02, 3.1726e-04, 3.7719e-02, 3.5251e-04, 6.3452e-03, 2.9963e-02,\n",
      "         4.0609e-01, 7.8504e-01, 6.3452e-03, 1.7625e-03, 1.0575e-03, 3.5251e-04,\n",
      "         3.5251e-04, 3.5251e-04],\n",
      "        [2.9128e-01, 2.2235e-04, 4.8916e-04, 2.2235e-04, 0.0000e+00, 2.2235e-04,\n",
      "         1.1340e-02, 1.3341e-04, 2.2235e-02, 8.8939e-04, 0.0000e+00, 3.9578e-02,\n",
      "         4.2668e-01, 8.5493e-01, 1.5564e-03, 0.0000e+00, 2.6682e-03, 2.2235e-04,\n",
      "         2.2235e-04, 0.0000e+00]]), tensor([2, 3, 3, 2, 0, 3, 0, 1, 3]))\n"
     ]
    }
   ],
   "source": [
    "print(traindata[25:34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "trainloader = DataLoader(traindata, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 20\n",
    "hidden_layers = 25\n",
    "output_dim = 4\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = nn.ReLU(input_dim, hidden_layers)\n",
    "        self.linear2 = nn.Softmax(hidden_layers, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ReLU.__init__() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clf \u001b[39m=\u001b[39m Network()\n",
      "Cell \u001b[1;32mIn[64], line 8\u001b[0m, in \u001b[0;36mNetwork.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[39msuper\u001b[39m(Network, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mReLU(input_dim, hidden_layers)\n\u001b[0;32m      9\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSoftmax(hidden_layers, output_dim)\n",
      "\u001b[1;31mTypeError\u001b[0m: ReLU.__init__() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "clf = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x00000174E274ACE0>\n"
     ]
    }
   ],
   "source": [
    "print(clf.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(clf.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 0.27244\n",
      "[2,   500] loss: 0.21557\n",
      "[3,   500] loss: 0.19430\n",
      "[4,   500] loss: 0.18478\n",
      "[5,   500] loss: 0.18463\n",
      "[6,   500] loss: 0.17728\n",
      "[7,   500] loss: 0.17804\n",
      "[8,   500] loss: 0.17659\n",
      "[9,   500] loss: 0.17732\n",
      "[10,   500] loss: 0.17021\n",
      "[11,   500] loss: 0.17044\n",
      "[12,   500] loss: 0.17359\n",
      "[13,   500] loss: 0.16884\n",
      "[14,   500] loss: 0.16745\n",
      "[15,   500] loss: 0.17201\n",
      "[16,   500] loss: 0.16850\n",
      "[17,   500] loss: 0.16738\n",
      "[18,   500] loss: 0.16501\n",
      "[19,   500] loss: 0.16852\n",
      "[20,   500] loss: 0.16503\n",
      "[21,   500] loss: 0.16362\n",
      "[22,   500] loss: 0.16599\n",
      "[23,   500] loss: 0.16295\n",
      "[24,   500] loss: 0.16299\n",
      "[25,   500] loss: 0.16106\n",
      "[26,   500] loss: 0.16584\n",
      "[27,   500] loss: 0.15880\n",
      "[28,   500] loss: 0.16300\n",
      "[29,   500] loss: 0.15913\n",
      "[30,   500] loss: 0.16248\n",
      "[31,   500] loss: 0.16030\n",
      "[32,   500] loss: 0.16127\n",
      "[33,   500] loss: 0.15717\n",
      "[34,   500] loss: 0.15808\n",
      "[35,   500] loss: 0.15610\n",
      "[36,   500] loss: 0.16036\n",
      "[37,   500] loss: 0.16135\n",
      "[38,   500] loss: 0.15651\n",
      "[39,   500] loss: 0.15684\n",
      "[40,   500] loss: 0.16049\n",
      "[41,   500] loss: 0.15395\n",
      "[42,   500] loss: 0.15504\n",
      "[43,   500] loss: 0.15404\n",
      "[44,   500] loss: 0.15712\n",
      "[45,   500] loss: 0.15840\n",
      "[46,   500] loss: 0.15665\n",
      "[47,   500] loss: 0.15547\n",
      "[48,   500] loss: 0.15846\n",
      "[49,   500] loss: 0.15349\n",
      "[50,   500] loss: 0.15833\n",
      "[51,   500] loss: 0.15926\n",
      "[52,   500] loss: 0.15756\n",
      "[53,   500] loss: 0.15395\n",
      "[54,   500] loss: 0.15658\n",
      "[55,   500] loss: 0.15282\n",
      "[56,   500] loss: 0.15493\n",
      "[57,   500] loss: 0.16097\n",
      "[58,   500] loss: 0.15652\n",
      "[59,   500] loss: 0.15118\n",
      "[60,   500] loss: 0.15648\n",
      "[61,   500] loss: 0.15595\n",
      "[62,   500] loss: 0.15635\n",
      "[63,   500] loss: 0.15540\n",
      "[64,   500] loss: 0.15527\n",
      "[65,   500] loss: 0.15231\n",
      "[66,   500] loss: 0.15417\n",
      "[67,   500] loss: 0.16071\n",
      "[68,   500] loss: 0.15294\n",
      "[69,   500] loss: 0.15406\n",
      "[70,   500] loss: 0.15450\n",
      "[71,   500] loss: 0.15101\n",
      "[72,   500] loss: 0.15250\n",
      "[73,   500] loss: 0.15471\n",
      "[74,   500] loss: 0.15312\n",
      "[75,   500] loss: 0.15351\n",
      "[76,   500] loss: 0.15761\n",
      "[77,   500] loss: 0.15247\n",
      "[78,   500] loss: 0.15747\n",
      "[79,   500] loss: 0.15352\n",
      "[80,   500] loss: 0.15534\n",
      "[81,   500] loss: 0.15023\n",
      "[82,   500] loss: 0.15519\n",
      "[83,   500] loss: 0.15414\n",
      "[84,   500] loss: 0.15047\n",
      "[85,   500] loss: 0.15408\n",
      "[86,   500] loss: 0.15667\n",
      "[87,   500] loss: 0.15467\n",
      "[88,   500] loss: 0.15114\n",
      "[89,   500] loss: 0.14939\n",
      "[90,   500] loss: 0.15741\n",
      "[91,   500] loss: 0.15158\n",
      "[92,   500] loss: 0.15182\n",
      "[93,   500] loss: 0.15129\n",
      "[94,   500] loss: 0.15099\n",
      "[95,   500] loss: 0.15402\n",
      "[96,   500] loss: 0.15274\n",
      "[97,   500] loss: 0.15605\n",
      "[98,   500] loss: 0.15384\n",
      "[99,   500] loss: 0.15350\n",
      "[100,   500] loss: 0.15066\n",
      "[101,   500] loss: 0.14984\n",
      "[102,   500] loss: 0.14982\n",
      "[103,   500] loss: 0.15146\n",
      "[104,   500] loss: 0.15164\n",
      "[105,   500] loss: 0.14749\n",
      "[106,   500] loss: 0.15332\n",
      "[107,   500] loss: 0.15275\n",
      "[108,   500] loss: 0.14823\n",
      "[109,   500] loss: 0.15330\n",
      "[110,   500] loss: 0.15051\n",
      "[111,   500] loss: 0.15276\n",
      "[112,   500] loss: 0.14876\n",
      "[113,   500] loss: 0.15029\n",
      "[114,   500] loss: 0.14866\n",
      "[115,   500] loss: 0.15099\n",
      "[116,   500] loss: 0.15332\n",
      "[117,   500] loss: 0.14955\n",
      "[118,   500] loss: 0.15553\n",
      "[119,   500] loss: 0.15477\n",
      "[120,   500] loss: 0.15249\n",
      "[121,   500] loss: 0.15067\n",
      "[122,   500] loss: 0.14876\n",
      "[123,   500] loss: 0.14991\n",
      "[124,   500] loss: 0.14869\n",
      "[125,   500] loss: 0.15726\n",
      "[126,   500] loss: 0.14912\n",
      "[127,   500] loss: 0.14845\n",
      "[128,   500] loss: 0.15000\n",
      "[129,   500] loss: 0.15025\n",
      "[130,   500] loss: 0.14788\n",
      "[131,   500] loss: 0.15322\n",
      "[132,   500] loss: 0.14939\n",
      "[133,   500] loss: 0.14909\n",
      "[134,   500] loss: 0.14879\n",
      "[135,   500] loss: 0.14488\n",
      "[136,   500] loss: 0.14515\n",
      "[137,   500] loss: 0.14686\n",
      "[138,   500] loss: 0.15138\n",
      "[139,   500] loss: 0.15442\n",
      "[140,   500] loss: 0.14732\n",
      "[141,   500] loss: 0.15355\n",
      "[142,   500] loss: 0.14919\n",
      "[143,   500] loss: 0.14822\n",
      "[144,   500] loss: 0.14746\n",
      "[145,   500] loss: 0.15479\n",
      "[146,   500] loss: 0.14649\n",
      "[147,   500] loss: 0.15501\n",
      "[148,   500] loss: 0.15003\n",
      "[149,   500] loss: 0.14838\n",
      "[150,   500] loss: 0.15184\n",
      "[151,   500] loss: 0.15080\n",
      "[152,   500] loss: 0.14782\n",
      "[153,   500] loss: 0.15274\n",
      "[154,   500] loss: 0.15084\n",
      "[155,   500] loss: 0.15559\n",
      "[156,   500] loss: 0.14592\n",
      "[157,   500] loss: 0.14902\n",
      "[158,   500] loss: 0.14732\n",
      "[159,   500] loss: 0.14817\n",
      "[160,   500] loss: 0.14449\n",
      "[161,   500] loss: 0.14968\n",
      "[162,   500] loss: 0.14850\n",
      "[163,   500] loss: 0.15011\n",
      "[164,   500] loss: 0.14774\n",
      "[165,   500] loss: 0.15042\n",
      "[166,   500] loss: 0.15120\n",
      "[167,   500] loss: 0.14941\n",
      "[168,   500] loss: 0.14733\n",
      "[169,   500] loss: 0.15401\n",
      "[170,   500] loss: 0.15063\n",
      "[171,   500] loss: 0.15104\n",
      "[172,   500] loss: 0.14879\n",
      "[173,   500] loss: 0.14365\n",
      "[174,   500] loss: 0.14679\n",
      "[175,   500] loss: 0.14443\n",
      "[176,   500] loss: 0.14838\n",
      "[177,   500] loss: 0.15058\n",
      "[178,   500] loss: 0.14574\n",
      "[179,   500] loss: 0.15140\n",
      "[180,   500] loss: 0.14800\n",
      "[181,   500] loss: 0.14816\n",
      "[182,   500] loss: 0.14918\n",
      "[183,   500] loss: 0.14800\n",
      "[184,   500] loss: 0.14763\n",
      "[185,   500] loss: 0.15043\n",
      "[186,   500] loss: 0.14878\n",
      "[187,   500] loss: 0.14861\n",
      "[188,   500] loss: 0.15034\n",
      "[189,   500] loss: 0.15010\n",
      "[190,   500] loss: 0.14750\n",
      "[191,   500] loss: 0.14558\n",
      "[192,   500] loss: 0.14704\n",
      "[193,   500] loss: 0.14824\n",
      "[194,   500] loss: 0.15073\n",
      "[195,   500] loss: 0.15119\n",
      "[196,   500] loss: 0.14638\n",
      "[197,   500] loss: 0.14509\n",
      "[198,   500] loss: 0.15242\n",
      "[199,   500] loss: 0.14982\n",
      "[200,   500] loss: 0.14526\n",
      "[201,   500] loss: 0.15053\n",
      "[202,   500] loss: 0.14622\n",
      "[203,   500] loss: 0.14465\n",
      "[204,   500] loss: 0.14650\n",
      "[205,   500] loss: 0.14278\n",
      "[206,   500] loss: 0.14957\n",
      "[207,   500] loss: 0.14400\n",
      "[208,   500] loss: 0.14672\n",
      "[209,   500] loss: 0.14724\n",
      "[210,   500] loss: 0.14651\n",
      "[211,   500] loss: 0.15080\n",
      "[212,   500] loss: 0.14754\n",
      "[213,   500] loss: 0.15061\n",
      "[214,   500] loss: 0.14384\n",
      "[215,   500] loss: 0.14912\n",
      "[216,   500] loss: 0.14161\n",
      "[217,   500] loss: 0.15779\n",
      "[218,   500] loss: 0.14459\n",
      "[219,   500] loss: 0.14804\n",
      "[220,   500] loss: 0.14683\n",
      "[221,   500] loss: 0.14703\n",
      "[222,   500] loss: 0.14699\n",
      "[223,   500] loss: 0.15232\n",
      "[224,   500] loss: 0.14408\n",
      "[225,   500] loss: 0.15020\n",
      "[226,   500] loss: 0.14730\n",
      "[227,   500] loss: 0.14554\n",
      "[228,   500] loss: 0.14489\n",
      "[229,   500] loss: 0.14697\n",
      "[230,   500] loss: 0.14394\n",
      "[231,   500] loss: 0.14739\n",
      "[232,   500] loss: 0.14613\n",
      "[233,   500] loss: 0.14106\n",
      "[234,   500] loss: 0.14429\n",
      "[235,   500] loss: 0.14541\n",
      "[236,   500] loss: 0.14985\n",
      "[237,   500] loss: 0.14435\n",
      "[238,   500] loss: 0.14505\n",
      "[239,   500] loss: 0.14768\n",
      "[240,   500] loss: 0.14483\n",
      "[241,   500] loss: 0.14860\n",
      "[242,   500] loss: 0.14280\n",
      "[243,   500] loss: 0.14909\n",
      "[244,   500] loss: 0.14586\n",
      "[245,   500] loss: 0.14481\n",
      "[246,   500] loss: 0.14274\n",
      "[247,   500] loss: 0.14713\n",
      "[248,   500] loss: 0.14714\n",
      "[249,   500] loss: 0.14477\n",
      "[250,   500] loss: 0.14530\n",
      "[251,   500] loss: 0.14412\n",
      "[252,   500] loss: 0.14855\n",
      "[253,   500] loss: 0.14626\n",
      "[254,   500] loss: 0.14425\n",
      "[255,   500] loss: 0.14405\n",
      "[256,   500] loss: 0.14685\n",
      "[257,   500] loss: 0.15575\n",
      "[258,   500] loss: 0.14459\n",
      "[259,   500] loss: 0.14388\n",
      "[260,   500] loss: 0.14800\n",
      "[261,   500] loss: 0.14654\n",
      "[262,   500] loss: 0.14338\n",
      "[263,   500] loss: 0.14395\n",
      "[264,   500] loss: 0.14667\n",
      "[265,   500] loss: 0.14556\n",
      "[266,   500] loss: 0.14308\n",
      "[267,   500] loss: 0.14481\n",
      "[268,   500] loss: 0.14422\n",
      "[269,   500] loss: 0.14281\n",
      "[270,   500] loss: 0.14447\n",
      "[271,   500] loss: 0.14142\n",
      "[272,   500] loss: 0.14225\n",
      "[273,   500] loss: 0.14338\n",
      "[274,   500] loss: 0.14744\n",
      "[275,   500] loss: 0.14265\n",
      "[276,   500] loss: 0.14225\n",
      "[277,   500] loss: 0.14491\n",
      "[278,   500] loss: 0.14266\n",
      "[279,   500] loss: 0.14475\n",
      "[280,   500] loss: 0.14475\n",
      "[281,   500] loss: 0.14121\n",
      "[282,   500] loss: 0.14819\n",
      "[283,   500] loss: 0.14980\n",
      "[284,   500] loss: 0.14091\n",
      "[285,   500] loss: 0.14698\n",
      "[286,   500] loss: 0.14379\n",
      "[287,   500] loss: 0.14210\n",
      "[288,   500] loss: 0.14187\n",
      "[289,   500] loss: 0.14333\n",
      "[290,   500] loss: 0.14559\n",
      "[291,   500] loss: 0.14098\n",
      "[292,   500] loss: 0.14320\n",
      "[293,   500] loss: 0.14305\n",
      "[294,   500] loss: 0.14280\n",
      "[295,   500] loss: 0.14534\n",
      "[296,   500] loss: 0.14222\n",
      "[297,   500] loss: 0.13963\n",
      "[298,   500] loss: 0.14712\n",
      "[299,   500] loss: 0.14424\n",
      "[300,   500] loss: 0.14307\n",
      "[301,   500] loss: 0.14624\n",
      "[302,   500] loss: 0.14226\n",
      "[303,   500] loss: 0.14221\n",
      "[304,   500] loss: 0.14519\n",
      "[305,   500] loss: 0.14436\n",
      "[306,   500] loss: 0.14957\n",
      "[307,   500] loss: 0.14334\n",
      "[308,   500] loss: 0.14045\n",
      "[309,   500] loss: 0.14267\n",
      "[310,   500] loss: 0.14671\n",
      "[311,   500] loss: 0.14137\n",
      "[312,   500] loss: 0.14362\n",
      "[313,   500] loss: 0.14205\n",
      "[314,   500] loss: 0.14432\n",
      "[315,   500] loss: 0.14670\n",
      "[316,   500] loss: 0.14345\n",
      "[317,   500] loss: 0.14761\n",
      "[318,   500] loss: 0.13924\n",
      "[319,   500] loss: 0.14401\n",
      "[320,   500] loss: 0.14241\n",
      "[321,   500] loss: 0.14351\n",
      "[322,   500] loss: 0.14379\n",
      "[323,   500] loss: 0.14166\n",
      "[324,   500] loss: 0.14275\n",
      "[325,   500] loss: 0.14163\n",
      "[326,   500] loss: 0.14746\n",
      "[327,   500] loss: 0.14295\n",
      "[328,   500] loss: 0.14622\n",
      "[329,   500] loss: 0.14456\n",
      "[330,   500] loss: 0.14234\n",
      "[331,   500] loss: 0.14229\n",
      "[332,   500] loss: 0.14477\n",
      "[333,   500] loss: 0.14587\n",
      "[334,   500] loss: 0.13858\n",
      "[335,   500] loss: 0.14050\n",
      "[336,   500] loss: 0.14088\n",
      "[337,   500] loss: 0.14053\n",
      "[338,   500] loss: 0.14335\n",
      "[339,   500] loss: 0.14081\n",
      "[340,   500] loss: 0.14476\n",
      "[341,   500] loss: 0.14785\n",
      "[342,   500] loss: 0.14079\n",
      "[343,   500] loss: 0.13991\n",
      "[344,   500] loss: 0.14258\n",
      "[345,   500] loss: 0.13771\n",
      "[346,   500] loss: 0.14147\n",
      "[347,   500] loss: 0.13896\n",
      "[348,   500] loss: 0.14102\n",
      "[349,   500] loss: 0.14706\n",
      "[350,   500] loss: 0.14142\n",
      "[351,   500] loss: 0.13801\n",
      "[352,   500] loss: 0.13985\n",
      "[353,   500] loss: 0.14342\n",
      "[354,   500] loss: 0.14177\n",
      "[355,   500] loss: 0.14254\n",
      "[356,   500] loss: 0.13953\n",
      "[357,   500] loss: 0.14081\n",
      "[358,   500] loss: 0.13625\n",
      "[359,   500] loss: 0.13878\n",
      "[360,   500] loss: 0.14156\n",
      "[361,   500] loss: 0.13795\n",
      "[362,   500] loss: 0.13885\n",
      "[363,   500] loss: 0.14508\n",
      "[364,   500] loss: 0.13813\n",
      "[365,   500] loss: 0.14330\n",
      "[366,   500] loss: 0.13853\n",
      "[367,   500] loss: 0.14223\n",
      "[368,   500] loss: 0.14070\n",
      "[369,   500] loss: 0.13674\n",
      "[370,   500] loss: 0.13640\n",
      "[371,   500] loss: 0.13619\n",
      "[372,   500] loss: 0.14075\n",
      "[373,   500] loss: 0.13788\n",
      "[374,   500] loss: 0.13813\n",
      "[375,   500] loss: 0.14110\n",
      "[376,   500] loss: 0.13985\n",
      "[377,   500] loss: 0.13711\n",
      "[378,   500] loss: 0.14040\n",
      "[379,   500] loss: 0.13814\n",
      "[380,   500] loss: 0.13999\n",
      "[381,   500] loss: 0.14099\n",
      "[382,   500] loss: 0.14057\n",
      "[383,   500] loss: 0.13781\n",
      "[384,   500] loss: 0.15520\n",
      "[385,   500] loss: 0.14054\n",
      "[386,   500] loss: 0.13790\n",
      "[387,   500] loss: 0.13646\n",
      "[388,   500] loss: 0.13527\n",
      "[389,   500] loss: 0.14079\n",
      "[390,   500] loss: 0.14355\n",
      "[391,   500] loss: 0.13738\n",
      "[392,   500] loss: 0.13483\n",
      "[393,   500] loss: 0.13962\n",
      "[394,   500] loss: 0.13608\n",
      "[395,   500] loss: 0.13728\n",
      "[396,   500] loss: 0.13740\n",
      "[397,   500] loss: 0.13965\n",
      "[398,   500] loss: 0.13948\n",
      "[399,   500] loss: 0.13683\n",
      "[400,   500] loss: 0.13830\n",
      "[401,   500] loss: 0.13602\n",
      "[402,   500] loss: 0.14187\n",
      "[403,   500] loss: 0.13979\n",
      "[404,   500] loss: 0.13720\n",
      "[405,   500] loss: 0.13622\n",
      "[406,   500] loss: 0.13850\n",
      "[407,   500] loss: 0.13974\n",
      "[408,   500] loss: 0.14214\n",
      "[409,   500] loss: 0.13402\n",
      "[410,   500] loss: 0.14323\n",
      "[411,   500] loss: 0.14074\n",
      "[412,   500] loss: 0.13852\n",
      "[413,   500] loss: 0.14673\n",
      "[414,   500] loss: 0.13590\n",
      "[415,   500] loss: 0.14271\n",
      "[416,   500] loss: 0.14838\n",
      "[417,   500] loss: 0.14311\n",
      "[418,   500] loss: 0.14229\n",
      "[419,   500] loss: 0.13583\n",
      "[420,   500] loss: 0.13926\n",
      "[421,   500] loss: 0.13746\n",
      "[422,   500] loss: 0.13335\n",
      "[423,   500] loss: 0.13934\n",
      "[424,   500] loss: 0.13942\n",
      "[425,   500] loss: 0.13770\n",
      "[426,   500] loss: 0.13636\n",
      "[427,   500] loss: 0.13471\n",
      "[428,   500] loss: 0.13634\n",
      "[429,   500] loss: 0.14324\n",
      "[430,   500] loss: 0.13931\n",
      "[431,   500] loss: 0.13864\n",
      "[432,   500] loss: 0.13803\n",
      "[433,   500] loss: 0.13350\n",
      "[434,   500] loss: 0.13735\n",
      "[435,   500] loss: 0.13830\n",
      "[436,   500] loss: 0.13785\n",
      "[437,   500] loss: 0.14194\n",
      "[438,   500] loss: 0.14052\n",
      "[439,   500] loss: 0.13905\n",
      "[440,   500] loss: 0.14037\n",
      "[441,   500] loss: 0.13895\n",
      "[442,   500] loss: 0.13537\n",
      "[443,   500] loss: 0.13981\n",
      "[444,   500] loss: 0.13792\n",
      "[445,   500] loss: 0.13592\n",
      "[446,   500] loss: 0.13754\n",
      "[447,   500] loss: 0.13734\n",
      "[448,   500] loss: 0.13632\n",
      "[449,   500] loss: 0.13449\n",
      "[450,   500] loss: 0.13879\n",
      "[451,   500] loss: 0.13316\n",
      "[452,   500] loss: 0.13694\n",
      "[453,   500] loss: 0.13608\n",
      "[454,   500] loss: 0.13818\n",
      "[455,   500] loss: 0.14047\n",
      "[456,   500] loss: 0.13763\n",
      "[457,   500] loss: 0.13504\n",
      "[458,   500] loss: 0.13533\n",
      "[459,   500] loss: 0.13590\n",
      "[460,   500] loss: 0.13303\n",
      "[461,   500] loss: 0.13718\n",
      "[462,   500] loss: 0.13583\n",
      "[463,   500] loss: 0.13688\n",
      "[464,   500] loss: 0.13939\n",
      "[465,   500] loss: 0.13750\n",
      "[466,   500] loss: 0.13878\n",
      "[467,   500] loss: 0.13777\n",
      "[468,   500] loss: 0.13799\n",
      "[469,   500] loss: 0.14287\n",
      "[470,   500] loss: 0.13158\n",
      "[471,   500] loss: 0.13724\n",
      "[472,   500] loss: 0.13632\n",
      "[473,   500] loss: 0.13660\n",
      "[474,   500] loss: 0.13604\n",
      "[475,   500] loss: 0.14336\n",
      "[476,   500] loss: 0.13958\n",
      "[477,   500] loss: 0.13809\n",
      "[478,   500] loss: 0.13844\n",
      "[479,   500] loss: 0.13974\n",
      "[480,   500] loss: 0.13933\n",
      "[481,   500] loss: 0.13643\n",
      "[482,   500] loss: 0.13724\n",
      "[483,   500] loss: 0.13535\n",
      "[484,   500] loss: 0.13682\n",
      "[485,   500] loss: 0.13740\n",
      "[486,   500] loss: 0.13952\n",
      "[487,   500] loss: 0.14130\n",
      "[488,   500] loss: 0.13469\n",
      "[489,   500] loss: 0.13524\n",
      "[490,   500] loss: 0.14064\n",
      "[491,   500] loss: 0.14082\n",
      "[492,   500] loss: 0.13573\n",
      "[493,   500] loss: 0.13798\n",
      "[494,   500] loss: 0.14159\n",
      "[495,   500] loss: 0.13864\n",
      "[496,   500] loss: 0.13903\n",
      "[497,   500] loss: 0.13335\n",
      "[498,   500] loss: 0.13620\n",
      "[499,   500] loss: 0.13430\n",
      "[500,   500] loss: 0.13632\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        input, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = clf(input)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss = running_loss + loss.item()\n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobile_price_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
